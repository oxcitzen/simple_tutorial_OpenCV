{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## io\n",
    "\n",
    "Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read image\n",
    "image_path = os.path.join('data', 'birds.jpg')\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# save image\n",
    "\n",
    "cv2.imwrite(os.path.join('.', 'data', 'birds_out.jpg'), img)\n",
    "\n",
    "# visualize image\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0) # wait until you press a key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "# visualize webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = webcam.read()\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(40) & 0xFF == ord('q'): # quen when press \"q\"\n",
    "        break\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operation\n",
    "\n",
    "Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427, 640, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join('data', 'bear.jpg'))\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "# original_image[crop_top:crop_bottom, crop_left:crop_right]\n",
    "\n",
    "cropped_img = img[107:320, 160:480]\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('cropped_img', cropped_img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427, 640, 3)\n",
      "(215, 320, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join('data', 'bear.jpg'))\n",
    "\n",
    "print(img.shape)  # height, width, number of channels\n",
    "\n",
    "resized_img = cv2.resize(img, (320, 215)) #width, height\n",
    "\n",
    "\n",
    "print(resized_img.shape)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('resized_img', resized_img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colorspaces\n",
    "\n",
    "color detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join('data', 'bird.jpg'))\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # convert from BGR to Gray scale \n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   # convert from BGR to RGB  (switching the color)\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)   # Convert from BGR to HSV\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_hsv', img_hsv)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread(os.path.join('data', 'cow-salt-peper.png')) # For this specific example, blurring is to remove noise\n",
    "\n",
    "k_size = 7\n",
    "img_blur = cv2.blur(img, (70, 70))     # (width, height) blurring\n",
    "\n",
    "img_blur2 = cv2.blur(img, (70, 1))\n",
    "img_blur3 = cv2.blur(img, (1, 70))\n",
    "\n",
    "img_gaussian_blur = cv2.GaussianBlur(img, (k_size, k_size), 5)\n",
    "img_median_blur = cv2.medianBlur(img, k_size)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_blur', img_blur)\n",
    "#cv2.imshow('img_blur', img_blur2)\n",
    "#cv2.imshow('img_blur', img_blur3)\n",
    "cv2.imshow('img_gaussian_blur', img_gaussian_blur)\n",
    "cv2.imshow('img_median_blur', img_median_blur)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold\n",
    "\n",
    "To segment image into different region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adaptive threshold\n",
    "\n",
    "img = cv2.imread(os.path.join('data', 'handwritten.png'))\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "adaptive_thresh = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 30) # adaptive\n",
    "ret, simple_thresh = cv2.threshold(img_gray, 80, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('adaptive_thresh', adaptive_thresh)\n",
    "cv2.imshow('simple_thresh', simple_thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(os.path.join('data', 'bear.jpg'))\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 80 is the lower limit, 255 is the upperlimit \n",
    "ret, thresh = cv2.threshold(img_gray, 80, 255, cv2.THRESH_BINARY)   \n",
    "# pixel under 80 will be converted to 0 and over 80 will be converted to 255\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# global threshold\n",
    "\n",
    "# The aim is to seperate the bear from the background\n",
    "\n",
    "img = cv2.imread(os.path.join('data', 'bear.jpg'))\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh = cv2.threshold(img_gray, 80, 255, cv2.THRESH_BINARY)   \n",
    "\n",
    "thresh = cv2.blur(thresh, (10, 10))         # blur\n",
    "ret, thresh_v2 = cv2.threshold(thresh, 80, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('thresh', thresh_v2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread(os.path.join('data', 'bad.jpg'))\n",
    "\n",
    "\n",
    "# Detect edges\n",
    "\n",
    "'''\n",
    "Edges with gradient magnitudes below the lower threshold are suppressed (considered not edges), \n",
    "while edges with gradient magnitudes above the upper threshold are considered strong edges. \n",
    "Edges with gradient magnitudes between the two thresholds are considered weak edges if they are connected to strong edges. \n",
    "The values 100 and 200 are commonly used as starting points for experimentation; you might need to adjust these values \n",
    "based on the characteristics of your images.\n",
    "'''\n",
    "img_edge = cv2.Canny(img, 100, 200)\n",
    "\n",
    "\n",
    "'''\n",
    "The dilation operation \"expands\" the white regions and fills in gaps or small holes in the binary image. \n",
    "It's often used to make edges thicker or to connect broken or disjointed segments.\n",
    "'''\n",
    "\n",
    "img_edge_d = cv2.dilate(img_edge, np.ones((3, 3), dtype=np.int8))   # making all the borders thicker\n",
    "\n",
    "\n",
    "'''\n",
    "the erosion operation \"shrinks\" the white regions and removes small features or noise from the image. \n",
    "It's often used as a preprocessing step before other operations like dilation or to refine the boundaries of objects in binary images.\n",
    "'''\n",
    "img_edge_e = cv2.erode(img_edge_d, np.ones((3, 3), dtype=np.int8))\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_edge', img_edge)\n",
    "cv2.imshow('img_edge_d', img_edge_d)\n",
    "cv2.imshow('img_edge_e', img_edge_e)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread(os.path.join('data', 'whiteboard.png'))\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "# line\n",
    "cv2.line(img, (100, 150), (300, 450), (0, 255, 0), 3)\n",
    "\n",
    "# rectangle\n",
    "'''\n",
    "(200, 350): This is the tuple representing the top-left corner of the rectangle, where the (x, y) coordinates are (200, 350).\n",
    "\n",
    "(450, 600): This is the tuple representing the bottom-right corner of the rectangle, where the (x, y) coordinates are (450, 600).\n",
    "\n",
    "(0, 0, 255): This is the color of the rectangle in BGR format (Blue, Green, Red). So, (0, 0, 255) represents pure red.\n",
    "\n",
    "-1: This is the thickness parameter. In this case, since it's set to -1, the rectangle will be filled with the specified color, \n",
    "creating a solid rectangle. If you were to use a positive integer for the thickness, the function would draw a rectangle with that thickness, \n",
    "but not fill it.\n",
    "'''\n",
    "cv2.rectangle(img, (200, 350), (450, 600), (0, 0, 255), -1)\n",
    "\n",
    "# circle\n",
    "cv2.circle(img, (800, 200), 75, (255, 0, 0), 10)\n",
    "\n",
    "# text\n",
    "cv2.putText(img, 'Hey you!', (600, 450), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 0), 10)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contours\n",
    "\n",
    "Contour detection is mainly used to determine the shape of closed objects as the process to find the contours is to check for the continuous points having same color intensity.\n",
    "\n",
    "Edge detection is carried by detecting the change in the color intensity.\n",
    "\n",
    "Contour is the edge closing an object. So you can think as higher level of edge detection.\n",
    "\n",
    "So if an edge define an object it becomes a contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread(os.path.join('data', 'birds.jpg'))\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY_INV) #Inverse take anything lower 127 to 255 and anything higher than 127 to 0.\n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours:\n",
    "    if cv2.contourArea(cnt) > 200:\n",
    "        # cv2.drawContours(img, cnt, -1, (0, 255, 0), 1)\n",
    "        \n",
    "        '''\n",
    "        The cv2.boundingRect() function is a utility provided by the OpenCV library in Python that is used to find the bounding rectangle of a contour. \n",
    "        A contour is a set of connected points that form the outline of an object or region in an image. The bounding rectangle is the smallest \n",
    "        rectangle that completely encloses the contour.\n",
    "        \n",
    "        The function returns four values:\n",
    "\n",
    "            x: This is the x-coordinate of the top-left corner of the bounding rectangle.\n",
    "\n",
    "            y: This is the y-coordinate of the top-left corner of the bounding rectangle.\n",
    "\n",
    "            width: This is the width of the bounding rectangle.\n",
    "\n",
    "            height: This is the height of the bounding rectangle.\n",
    "        '''\n",
    "\n",
    "        x1, y1, w, h = cv2.boundingRect(cnt)\n",
    "        \n",
    "        # (x1, y1)- top left coor, (x1 + w, y1 + h) bottom right\n",
    "        cv2.rectangle(img, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2) # plot onto the original image\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('thresh', thresh)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
